{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "ct6xY1DP3VNt"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# numpy and matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "from PIL import Image\n",
    "import sys\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdist(e, squared=False, eps=1e-12):\n",
    "    e_square = e.pow(2).sum(dim=1)\n",
    "    prod = e @ e.t()\n",
    "    res = (e_square.unsqueeze(1) + e_square.unsqueeze(0) - 2 * prod).clamp(min=eps)\n",
    "\n",
    "    if not squared:\n",
    "        res = res.sqrt()\n",
    "\n",
    "    res = res.clone()\n",
    "    res[range(len(e)), range(len(e))] = 0\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "X9FbV_O94JEz"
   },
   "outputs": [],
   "source": [
    "# initialize for  each parameters\n",
    "DATASET = 'CIFAR10'\n",
    "BATCH_SIZE = 100\n",
    "NUM_WORKERS = 2\n",
    "\n",
    "WEIGHT_DECAY = 0.007\n",
    "LEARNING_RATE = 0.01\n",
    "MOMENTUM = 0.9\n",
    "\n",
    "SCHEDULER_STEPS = 100\n",
    "SCHEDULER_GAMMA = 0.1\n",
    "\n",
    "SEED = 1\n",
    "\n",
    "EPOCH = 150\n",
    "\n",
    "KD_LAMBDA = 2.0\n",
    "\n",
    "TRIPLET_MARGINE = 5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/ssd_scratch/cvit/sashank.sridhar\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "veXjheeA4LhC"
   },
   "outputs": [],
   "source": [
    "# fixing the seed\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JnVR6kht4NZh",
    "outputId": "1a5b33ee-df16-440e-d107-ee70483ce6ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu mode\n"
     ]
    }
   ],
   "source": [
    "# check if gpu is available\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    print(\"gpu mode\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"cpu mode\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "nS54WHBh4Pdg"
   },
   "outputs": [],
   "source": [
    "# the name of results files\n",
    "codename = 'cifar10_hkd_rd'\n",
    "\n",
    "fnnname = codename + \"_fnn_model\"\n",
    "\n",
    "total_loss_name = codename + \"_total_loss\"\n",
    "soft_loss_name = codename + \"_soft_loss\"\n",
    "tri_loss_name = codename + \"_tri_loss\"\n",
    "acc_name = codename + \"_accuracy\"\n",
    "\n",
    "result_name = codename + \"_result\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "-uCnZzVc4S-k"
   },
   "outputs": [],
   "source": [
    "class Datasets(object):\n",
    "    def __init__(self, dataset_name, batch_size = 100, num_workers = 2, transform = None, shuffle = True):\n",
    "        self.dataset_name = dataset_name\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "        self.transform = transform\n",
    "        self.shuffle = shuffle\n",
    "        \n",
    "    def create(self, path = None):\n",
    "        print(\"Dataset :\",self.dataset_name)\n",
    "        if self.transform is None:\n",
    "                self.transform = transforms.Compose([transforms.ToTensor()])\n",
    "        \n",
    "        \n",
    "        if path is None:\n",
    "            path = \"./\"+self.dataset_name+\"Dataset/data\"\n",
    "        \n",
    "        \n",
    "        if self.dataset_name == \"MNIST\":\n",
    "            trainset = torchvision.datasets.MNIST(root = path,\n",
    "                                       train = True, download = True, transform = self.transform)\n",
    "            testset = torchvision.datasets.MNIST(root = path,\n",
    "                                                 train = False, download = True, transform = self.transform)\n",
    "            classes = list(range(10))\n",
    "            base_labels = trainset.classes\n",
    "            \n",
    "        elif self.dataset_name == \"FashionMNIST\":\n",
    "            trainset = torchvision.datasets.FashionMNIST(root = path,\n",
    "                                       train = True, download = True, transform = self.transform)\n",
    "            testset = torchvision.datasets.FashionMNIST(root = path,\n",
    "                                                 train = False, download = True, transform = self.transform)\n",
    "            classes = list(range(10))\n",
    "            base_labels = trainset.classes\n",
    "            \n",
    "        elif self.dataset_name == \"CIFAR10\":\n",
    "            trainset = torchvision.datasets.CIFAR10(root = path,\n",
    "                                       train = True, download = True, transform = self.transform)\n",
    "            testset = torchvision.datasets.CIFAR10(root = path,\n",
    "                                                 train = False, download = True, transform = self.transform)\n",
    "            classes = list(range(10))\n",
    "            base_labels = trainset.classes\n",
    "            \n",
    "        elif self.dataset_name == \"CIFAR100\":\n",
    "            trainset = torchvision.datasets.CIFAR100(root = path,\n",
    "                                       train = True, download = True, transform = self.transform)\n",
    "            testset = torchvision.datasets.CIFAR100(root = path,\n",
    "                                                 train = False, download = True, transform = self.transform)\n",
    "            classes = list(range(100))\n",
    "            base_labels = trainset.classes\n",
    "        \n",
    "        else:\n",
    "            raise KeyError(\"Unknown dataset: {}\".format(self.dataset_name))\n",
    "            \n",
    "        \n",
    "        trainloader = torch.utils.data.DataLoader(trainset, batch_size = self.batch_size,\n",
    "                        shuffle = self.shuffle, num_workers = self.num_workers)\n",
    "        \n",
    "        if testset is not None:\n",
    "            testloader = torch.utils.data.DataLoader(testset, batch_size = self.batch_size,\n",
    "                        shuffle = False, num_workers = self.num_workers)\n",
    "        else:\n",
    "            testloader = None\n",
    "            \n",
    "            \n",
    "        return [trainloader, testloader, classes, base_labels, trainset, testset]\n",
    "    \n",
    "    def worker_init_fn(self, worker_id):                                                          \n",
    "        np.random.seed(worker_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 118,
     "referenced_widgets": [
      "1684bb7895874598b0cb3c8344ce4851",
      "185cff25aff34094a39c57dbf63e1975",
      "cd02fad8000c476ebea64496837d52c3",
      "4e65525bb7fa4638964b72c3490847fb",
      "cd38ab54d77d4b0eb9f027e96800096a",
      "f77ef129c307426b9aaf83dd61dcc5d5",
      "7a07a97d997744fab665c96c1f5fe579",
      "9c23bae705e54a6084b3fd4282a4ecdc",
      "6c49593980e64b7fac5d3ce14efb325c",
      "85f298067f814dd19f731aebea5d6e96",
      "b372328dca9b49d4960f05df1a50d60a"
     ]
    },
    "id": "qLqmqtjc4ZzB",
    "outputId": "fab5611e-6dc2-4f95-b78f-cbb348fd6daf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset : CIFAR10\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# load the data set\n",
    "instance_datasets = Datasets(DATASET, BATCH_SIZE, NUM_WORKERS, shuffle = False)\n",
    "data_sets = instance_datasets.create()\n",
    "\n",
    "#trainloader = data_sets[0]\n",
    "#testloader = data_sets[1]\n",
    "classes = data_sets[2]\n",
    "based_labels = data_sets[3]\n",
    "trainset = data_sets[4]\n",
    "testset = data_sets[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "E6IHN1HX4e-K"
   },
   "outputs": [],
   "source": [
    "class KDTripletDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset):\n",
    "        self.dataset = dataset\n",
    "        \n",
    "        data = dataset.data\n",
    "        labels = dataset.targets\n",
    "        if type(labels) is not torch.Tensor:\n",
    "                labels = torch.tensor(labels)\n",
    "        \n",
    "        # make label set 0-9\n",
    "        labels_set = set(labels.numpy())\n",
    "        \n",
    "        # make the indices excepted each classes\n",
    "        label_to_indices = {label : np.where(labels.numpy() != label)[0] for label in labels_set}\n",
    "        \n",
    "        if self.dataset.train:\n",
    "            self.negative_indices = label_to_indices\n",
    "        else:\n",
    "            self.negative_indices = [[np.random.choice(label_to_indices[labels[i].item()])] for i in range(len(data))]\n",
    "        \n",
    "\n",
    "            \n",
    "    def __getitem__(self, index):\n",
    "        if self.dataset.train:\n",
    "            img1_2, label1_2 = self.dataset[index]\n",
    "            if type(label1_2) is not torch.Tensor:\n",
    "                label1_2 = torch.tensor(label1_2)\n",
    "            img3, label3 = self.dataset[np.random.choice(self.negative_indices[label1_2.item()])]\n",
    "        else:\n",
    "            img1_2, label1_2 = self.dataset[index]\n",
    "            img3, label3 = self.dataset[self.negative_indices[index][0]]\n",
    "        \n",
    "            \n",
    "        return (img1_2, img3), (label1_2, label3)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "9GMBjWBp4lWX"
   },
   "outputs": [],
   "source": [
    "# use the KD Triplet Dataset by using above dataset\n",
    "tri_trainset = KDTripletDataset(trainset)\n",
    "tri_testset = KDTripletDataset(testset)\n",
    "tri_trainloader = torch.utils.data.DataLoader(tri_trainset, batch_size = BATCH_SIZE, shuffle = True, num_workers = NUM_WORKERS)\n",
    "tri_testloader = torch.utils.data.DataLoader(tri_testset, batch_size = BATCH_SIZE, shuffle = False, num_workers = NUM_WORKERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "eN-5D93D4t6r"
   },
   "outputs": [],
   "source": [
    "class Net_teacher(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net_teacher, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3,32,3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32,32,3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(32,64, 3, padding=1)\n",
    "        self.conv4 = nn.Conv2d(64,64, 3, padding=1)\n",
    "        self.conv5 = nn.Conv2d(64,128, 3, padding=1)\n",
    "        self.fc1 = nn.Linear(128*4*4, 512)\n",
    "        self.fc2 = nn.Linear(512, 128)\n",
    "        self.fc3 = nn.Linear(128, 10)\n",
    "\n",
    "        self.batchnorm1 = nn.BatchNorm2d(32)\n",
    "        self.batchnorm2 = nn.BatchNorm2d(32)\n",
    "        self.batchnorm3 = nn.BatchNorm2d(64)\n",
    "        self.batchnorm4 = nn.BatchNorm2d(64)\n",
    "        self.batchnorm5 = nn.BatchNorm2d(128)\n",
    "\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.batchnorm1(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.batchnorm2(x)\n",
    "        x = self.pool(x)\n",
    "\n",
    "        x = self.relu(self.conv3(x))\n",
    "        x = self.batchnorm3(x)\n",
    "        x = self.relu(self.conv4(x))\n",
    "        x = self.batchnorm4(x)\n",
    "        x = self.relu(self.conv5(x))\n",
    "        x = self.batchnorm5(x)\n",
    "        x = self.pool(x)\n",
    "\n",
    "        x = x.view(-1, 128 * 4 * 4)\n",
    "        x = self.dropout(self.relu(self.fc1(x)))\n",
    "        x = self.dropout(self.relu(self.fc2(x)))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Net_student(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net_student, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 32, 3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.fc1 = nn.Linear(64 * 4 * 4, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "\n",
    "        x = self.relu(self.conv3(x))\n",
    "        x = self.pool(x)\n",
    "        \n",
    "        x = x.view(-1, 64 * 4 * 4)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "2Vay8DfU4y3z"
   },
   "outputs": [],
   "source": [
    "# network and criterions\n",
    "model_t = Net_teacher().to(device)\n",
    "model_s = Net_student().to(device)\n",
    "\n",
    "model_t.load_state_dict(torch.load(\"cnn_alex.pkl\"))\n",
    "\n",
    "optimizer = optim.SGD(model_s.parameters(), lr=LEARNING_RATE, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=SCHEDULER_STEPS, gamma=SCHEDULER_GAMMA)\n",
    "\n",
    "soft_criterion = nn.CrossEntropyLoss()\n",
    "triplet_loss = nn.TripletMarginLoss(margin=TRIPLET_MARGINE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "18uppIPYXFG2"
   },
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
    "    def __init__(self, patience=7, verbose=False, delta=0, path='checkpoint.pt', trace_func=print):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): How long to wait after last time validation loss improved.\n",
    "                            Default: 7\n",
    "            verbose (bool): If True, prints a message for each validation loss improvement. \n",
    "                            Default: False\n",
    "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
    "                            Default: 0\n",
    "            path (str): Path for the checkpoint to be saved to.\n",
    "                            Default: 'checkpoint.pt'\n",
    "            trace_func (function): trace print function.\n",
    "                            Default: print            \n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.delta = delta\n",
    "        self.path = path\n",
    "        self.trace_func = trace_func\n",
    "    def __call__(self, val_loss, model):\n",
    "\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        '''Saves model when validation loss decrease.'''\n",
    "        if self.verbose:\n",
    "            self.trace_func(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "        torch.save(model.state_dict(), self.path)\n",
    "        self.val_loss_min = val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RkdDistance(nn.Module):\n",
    "    def forward(self, student, teacher):\n",
    "        with torch.no_grad():\n",
    "            t_d = pdist(teacher, squared=False)\n",
    "            mean_td = t_d[t_d>0].mean()\n",
    "            t_d = t_d / mean_td\n",
    "\n",
    "        d = pdist(student, squared=False)\n",
    "        mean_d = d[d>0].mean()\n",
    "        d = d / mean_d\n",
    "\n",
    "        loss = F.smooth_l1_loss(d, t_d, reduction='elementwise_mean')\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RKdAngle(nn.Module):\n",
    "    def forward(self, student, teacher):\n",
    "        # N x C\n",
    "        # N x N x C\n",
    "\n",
    "        with torch.no_grad():\n",
    "            td = (teacher.unsqueeze(0) - teacher.unsqueeze(1))\n",
    "            norm_td = F.normalize(td, p=2, dim=2)\n",
    "            t_angle = torch.bmm(norm_td, norm_td.transpose(1, 2)).view(-1)\n",
    "\n",
    "        sd = (student.unsqueeze(0) - student.unsqueeze(1))\n",
    "        norm_sd = F.normalize(sd, p=2, dim=2)\n",
    "        s_angle = torch.bmm(norm_sd, norm_sd.transpose(1, 2)).view(-1)\n",
    "\n",
    "        loss = F.smooth_l1_loss(s_angle, t_angle, reduction='elementwise_mean')\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HardDarkRank(nn.Module):\n",
    "    def __init__(self, alpha=3, beta=3, permute_len=4):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.permute_len = permute_len\n",
    "\n",
    "    def forward(self, student, teacher):\n",
    "        score_teacher = -1 * self.alpha * pdist(teacher, squared=False).pow(self.beta)\n",
    "        score_student = -1 * self.alpha * pdist(student, squared=False).pow(self.beta)\n",
    "\n",
    "        permute_idx = score_teacher.sort(dim=1, descending=True)[1][:, 1:(self.permute_len+1)]\n",
    "        ordered_student = torch.gather(score_student, 1, permute_idx)\n",
    "\n",
    "        log_prob = (ordered_student - torch.stack([torch.logsumexp(ordered_student[:, i:], dim=1) for i in range(permute_idx.size(1))], dim=1)).sum(dim=1)\n",
    "        loss = (-1 * log_prob).mean()\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "MZpk2uTX44GD"
   },
   "outputs": [],
   "source": [
    "class NetworkFit(object):\n",
    "    def __init__(self, model_t, model_s, optimizer, soft_criterion, distance_criterion,angle_criterion, dark_criterion, triplet_loss):\n",
    "        self.model_t = model_t\n",
    "        self.model_s = model_s\n",
    "        self.optimizer = optimizer\n",
    "        \n",
    "        self.soft_criterion = soft_criterion\n",
    "        self.triplet_loss = triplet_loss\n",
    "        \n",
    "        self.distance_criterion = distance_criterion\n",
    "        \n",
    "        self.angle_criterion = angle_criterion\n",
    "        \n",
    "        self.dark_criterion = dark_criterion\n",
    "        \n",
    "        self.model_t.eval()\n",
    "        \n",
    "\n",
    "    def train(self, inputs, labels, kd_lambda = 2.0):\n",
    "        self.optimizer.zero_grad()\n",
    "        self.model_s.train()\n",
    "\n",
    "        img1_t = inputs[0]\n",
    "        img2_s = inputs[1]\n",
    "        img3_s = inputs[2]\n",
    "        \n",
    "        label1_t = labels[0]\n",
    "        label2_s = labels[1]\n",
    "        label3_s = labels[2]\n",
    "        \n",
    "        out1_t = self.model_t(img1_t)\n",
    "        out2_s = self.model_s(img2_s)\n",
    "        out3_s = self.model_s(img3_s)\n",
    "        \n",
    "        soft_loss = self.soft_criterion(out2_s, label2_s)\n",
    "        trip_loss = self.triplet_loss(out1_t, out2_s, out3_s)\n",
    "\n",
    "        temperature=1.0\n",
    "        \n",
    "        soft_log_probs = F.log_softmax(out2_s / temperature, dim=1)\n",
    "        # soft_targets = F.softmax(self.cached_teacher_logits[minibatch_id] / self.temperature)\n",
    "        soft_targets = F.softmax(out1_t / temperature, dim=1)\n",
    "\n",
    "        distillation_loss = F.kl_div(soft_log_probs, soft_targets.detach(), reduction='batchmean')\n",
    "        \n",
    "        distillation_loss_scaled = distillation_loss * temperature ** 2\n",
    "        \n",
    "        dist_ratio = 1.0\n",
    "        \n",
    "        dist_loss = dist_ratio * self.distance_criterion(out2_s, out1_t)\n",
    "        \n",
    "        angle_ratio = 1.0\n",
    "        \n",
    "        angle_loss = angle_ratio * self.angle_criterion(out2_s, out1_t)\n",
    "        \n",
    "        dark_ratio = 1.0\n",
    "        \n",
    "        dark_loss = dark_ratio * self.dark_criterion(out2_s, out1_t)\n",
    "\n",
    "        loss = soft_loss + kd_lambda*trip_loss + distillation_loss_scaled + dist_loss + angle_loss + dark_loss\n",
    " \n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "            \n",
    "            \n",
    "    def test(self, inputs, labels, kd_lambda = 2.0):\n",
    "        self.model_s.eval()\n",
    "        \n",
    "        img1_t = inputs[0]\n",
    "        img2_s = inputs[1]\n",
    "        img3_s = inputs[2]\n",
    "        \n",
    "        label1_t = labels[0]\n",
    "        label2_s = labels[1]\n",
    "        label3_s = labels[2]\n",
    "        \n",
    "        out1_t = self.model_t(img1_t)\n",
    "        out2_s = self.model_s(img2_s)\n",
    "        out3_s = self.model_s(img3_s)\n",
    "        \n",
    "        soft_loss = self.soft_criterion(out2_s, label2_s)\n",
    "        trip_loss = self.triplet_loss(out1_t, out2_s, out3_s)\n",
    "        \n",
    "        temperature=1.0\n",
    "        \n",
    "        soft_log_probs = F.log_softmax(out2_s / temperature, dim=1)\n",
    "        # soft_targets = F.softmax(self.cached_teacher_logits[minibatch_id] / self.temperature)\n",
    "        soft_targets = F.softmax(out1_t / temperature, dim=1)\n",
    "\n",
    "        distillation_loss = F.kl_div(soft_log_probs, soft_targets.detach(), reduction='batchmean')\n",
    "        \n",
    "        distillation_loss_scaled = distillation_loss * temperature ** 2\n",
    "\n",
    "        dist_ratio = 1.0\n",
    "        \n",
    "        dist_loss = dist_ratio * self.distance_criterion(out2_s, out1_t)\n",
    "        \n",
    "        angle_ratio = 1.0\n",
    "        \n",
    "        angle_loss = angle_ratio * self.angle_criterion(out2_s, out1_t)\n",
    "        \n",
    "        dark_ratio = 1.0\n",
    "        \n",
    "        dark_loss = dark_ratio * self.dark_criterion(out2_s, out1_t)\n",
    "\n",
    "        loss = soft_loss + kd_lambda*trip_loss + distillation_loss_scaled + dist_loss + angle_loss + dark_loss\n",
    "        \n",
    "        _, predicted = out2_s.max(1)\n",
    "        correct = (predicted == label2_s).sum().item()\n",
    "        \n",
    "        return [loss.item(), soft_loss.item(), trip_loss.item()], [correct]\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_criterion = RkdDistance()\n",
    "angle_criterion = RKdAngle()\n",
    "dark_criterion = HardDarkRank()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "AHRH5T6J5VP-"
   },
   "outputs": [],
   "source": [
    "# fit for training and test\n",
    "fit = NetworkFit(model_t, model_s, optimizer, soft_criterion,dist_criterion,angle_criterion,dark_criterion, triplet_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "j9BF3qbE5W--"
   },
   "outputs": [],
   "source": [
    "class Score(object):\n",
    "    def __init__(self, score = 0):\n",
    "        self.score = score\n",
    "        \n",
    "    def sum_score(self, score):\n",
    "        self.score += score\n",
    "    \n",
    "    def set_score(self, score):\n",
    "        self.score = score\n",
    "    \n",
    "    def init_score(self):\n",
    "        self.score = 0\n",
    "    \n",
    "    def get_score(self):\n",
    "        return self.score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "U0gzfZ-n5hA0"
   },
   "outputs": [],
   "source": [
    "class ScoreCalc(object):\n",
    "    def __init__(self, losses, corrects, batch_size):\n",
    "        self.losses = losses\n",
    "        self.corrects = corrects\n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        self.len_l = len(losses)\n",
    "        self.len_c = len(corrects)\n",
    "        \n",
    "        self.train_losses = [[] for l in range(self.len_l)]\n",
    "        self.train_corrects = [[] for c in range(self.len_c)]\n",
    "        \n",
    "        self.test_losses = [[] for l in range(self.len_l)]\n",
    "        self.test_corrects = [[] for c in range(self.len_c)]\n",
    "\n",
    "        patience = 50\n",
    "\n",
    "        self.early_stopping = EarlyStopping(patience=patience, verbose=True)\n",
    "       \n",
    "    \n",
    "    def calc_sum(self, losses, corrects):\n",
    "        if len(losses) != len(self.losses):\n",
    "            print(\"warning : len(losses) != len(self.losses)\")\n",
    "            sys.exit()\n",
    "        if len(corrects) != len(self.corrects):\n",
    "            print(\"warning : len(corrects) != len(self.corrects)\")\n",
    "            sys.exit()\n",
    "        \n",
    "        for l in range(self.len_l):\n",
    "            self.losses[l].sum_score(losses[l])\n",
    "        \n",
    "        for c in range(self.len_c):\n",
    "            self.corrects[c].sum_score(corrects[c])\n",
    "        \n",
    "        return self.losses, self.corrects\n",
    "    \n",
    "    \n",
    "    def score_del(self):\n",
    "        for loss in self.losses:\n",
    "            loss.init_score()\n",
    "        for correct in self.corrects:\n",
    "            correct.init_score()\n",
    "\n",
    "        \n",
    "    def score_print(self, data_num, train = True):\n",
    "        if train:\n",
    "            print(\"train mean loss={}, accuracy={}\".format(self.losses[0].get_score()*self.batch_size/data_num, float(self.corrects[0].get_score()/data_num)))\n",
    "        else:\n",
    "            \n",
    "            print(\"test mean loss={}, accuracy={}\".format(self.losses[0].get_score()*self.batch_size/data_num, float(self.corrects[0].get_score()/data_num)))\n",
    "            self.early_stopping(self.losses[0].get_score()*self.batch_size/data_num, model_s)\n",
    "        \n",
    "            if self.early_stopping.early_stop:\n",
    "                print(\"Early stopping\")\n",
    "                return True\n",
    "            else:\n",
    "              return False\n",
    "\n",
    "            \n",
    "    def score_append(self, data_num, train = True):\n",
    "        if train:\n",
    "            for l in range(self.len_l):\n",
    "                self.train_losses[l].append(self.losses[l].get_score()*self.batch_size/data_num)\n",
    "            for c in range(self.len_c):\n",
    "                self.train_corrects[c].append(float(self.corrects[c].get_score()/data_num))\n",
    "        else:\n",
    "            for l in range(self.len_l):\n",
    "                self.test_losses[l].append(self.losses[l].get_score()*self.batch_size/data_num)\n",
    "            for c in range(self.len_c):\n",
    "                self.test_corrects[c].append(float(self.corrects[c].get_score()/data_num))\n",
    "    \n",
    "    \n",
    "    def get_value(self, train = True):\n",
    "        if train:\n",
    "            return self.train_losses, self.train_corrects\n",
    "        else:\n",
    "            return self.test_losses, self.test_corrects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "W4ogtBkH5cHu"
   },
   "outputs": [],
   "source": [
    "# to manage all scores\n",
    "loss = Score()\n",
    "loss_s = Score()\n",
    "loss_t = Score()\n",
    "correct = Score()\n",
    "score_loss = [loss, loss_s, loss_t]\n",
    "score_correct = [correct]\n",
    "sc = ScoreCalc(score_loss, score_correct, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rxeumM7g5czi",
    "outputId": "ce7864d0-f67e-4fe8-dd88-9b9aa803ab43",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1\n",
      "Iteration: 10/500"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home2/sashank.sridhar/miniconda3/envs/TripletLoss/lib/python3.9/site-packages/torch/nn/_reduction.py:13: UserWarning: reduction='elementwise_mean' is deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(\"reduction='elementwise_mean' is deprecated, please use reduction='mean' instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 500/500Train Loss Calc\n",
      "Iteration: 500/500train mean loss=16.11571481895447, accuracy=0.45024\n",
      "Test Loss Calc\n",
      "Iteration: 100/100test mean loss=15.821929206848145, accuracy=0.4464\n",
      "Validation loss decreased (inf --> 15.821929).  Saving model ...\n",
      "epoch 2\n",
      "Iteration: 500/500Train Loss Calc\n",
      "Iteration: 500/500train mean loss=16.01675016784668, accuracy=0.398\n",
      "Test Loss Calc\n",
      "Iteration: 100/100test mean loss=15.727437324523926, accuracy=0.3967\n",
      "Validation loss decreased (15.821929 --> 15.727437).  Saving model ...\n",
      "epoch 3\n",
      "Iteration: 500/500Train Loss Calc\n",
      "Iteration: 500/500train mean loss=15.697404472351074, accuracy=0.57332\n",
      "Test Loss Calc\n",
      "Iteration: 100/100test mean loss=15.423160400390625, accuracy=0.5633\n",
      "Validation loss decreased (15.727437 --> 15.423160).  Saving model ...\n",
      "epoch 4\n",
      "Iteration: 500/500Train Loss Calc\n",
      "Iteration: 500/500train mean loss=15.634045734405518, accuracy=0.55906\n",
      "Test Loss Calc\n",
      "Iteration: 100/100test mean loss=15.316540145874024, accuracy=0.5564\n",
      "Validation loss decreased (15.423160 --> 15.316540).  Saving model ...\n",
      "epoch 5\n",
      "Iteration: 500/500Train Loss Calc\n",
      "Iteration: 500/500train mean loss=15.591820257186889, accuracy=0.58452\n",
      "Test Loss Calc\n",
      "Iteration: 100/100test mean loss=15.317573032379151, accuracy=0.5682\n",
      "EarlyStopping counter: 1 out of 50\n",
      "epoch 6\n",
      "Iteration: 500/500Train Loss Calc\n",
      "Iteration: 500/500train mean loss=15.506074317932129, accuracy=0.59752\n",
      "Test Loss Calc\n",
      "Iteration: 100/100test mean loss=15.238798828125, accuracy=0.5881\n",
      "Validation loss decreased (15.316540 --> 15.238799).  Saving model ...\n",
      "epoch 7\n",
      "Iteration: 500/500Train Loss Calc\n",
      "Iteration: 500/500train mean loss=15.730692209243774, accuracy=0.52316\n",
      "Test Loss Calc\n",
      "Iteration: 100/100test mean loss=15.463959159851074, accuracy=0.5191\n",
      "EarlyStopping counter: 1 out of 50\n",
      "epoch 8\n",
      "Iteration: 500/500Train Loss Calc\n",
      "Iteration: 500/500train mean loss=15.531091205596924, accuracy=0.61388\n",
      "Test Loss Calc\n",
      "Iteration: 100/100test mean loss=15.256491422653198, accuracy=0.6039\n",
      "EarlyStopping counter: 2 out of 50\n",
      "epoch 9\n",
      "Iteration: 500/500Train Loss Calc\n",
      "Iteration: 500/500train mean loss=15.534938497543335, accuracy=0.59366\n",
      "Test Loss Calc\n",
      "Iteration: 100/100test mean loss=15.301581563949584, accuracy=0.5744\n",
      "EarlyStopping counter: 3 out of 50\n",
      "epoch 10\n",
      "Iteration: 500/500Train Loss Calc\n",
      "Iteration: 500/500train mean loss=15.562707265853883, accuracy=0.61118\n",
      "Test Loss Calc\n",
      "Iteration: 100/100test mean loss=15.317150545120239, accuracy=0.598\n",
      "EarlyStopping counter: 4 out of 50\n",
      "epoch 11\n",
      "Iteration: 500/500Train Loss Calc\n",
      "Iteration: 500/500train mean loss=15.663920000076294, accuracy=0.48008\n",
      "Test Loss Calc\n",
      "Iteration: 100/100test mean loss=15.419254331588744, accuracy=0.4602\n",
      "EarlyStopping counter: 5 out of 50\n",
      "epoch 12\n",
      "Iteration: 500/500Train Loss Calc\n",
      "Iteration: 500/500train mean loss=15.3868031539917, accuracy=0.62298\n",
      "Test Loss Calc\n",
      "Iteration: 100/100test mean loss=15.135476741790772, accuracy=0.6052\n",
      "Validation loss decreased (15.238799 --> 15.135477).  Saving model ...\n",
      "epoch 13\n",
      "Iteration: 500/500Train Loss Calc\n",
      "Iteration: 500/500train mean loss=15.29187108039856, accuracy=0.644\n",
      "Test Loss Calc\n",
      "Iteration: 100/100test mean loss=15.075258264541626, accuracy=0.6277\n",
      "Validation loss decreased (15.135477 --> 15.075258).  Saving model ...\n",
      "epoch 14\n",
      "Iteration: 500/500Train Loss Calc\n",
      "Iteration: 500/500train mean loss=15.274990579605102, accuracy=0.64536\n",
      "Test Loss Calc\n",
      "Iteration: 100/100test mean loss=15.01380696296692, accuracy=0.6321\n",
      "Validation loss decreased (15.075258 --> 15.013807).  Saving model ...\n",
      "epoch 15\n",
      "Iteration: 500/500Train Loss Calc\n",
      "Iteration: 500/500train mean loss=15.473596378326416, accuracy=0.62524\n",
      "Test Loss Calc\n",
      "Iteration: 100/100test mean loss=15.239819688796997, accuracy=0.6113\n",
      "EarlyStopping counter: 1 out of 50\n",
      "epoch 16\n",
      "Iteration: 500/500Train Loss Calc\n",
      "Iteration: 500/500train mean loss=15.33519049835205, accuracy=0.58646\n",
      "Test Loss Calc\n",
      "Iteration: 100/100test mean loss=15.113003969192505, accuracy=0.5682\n",
      "EarlyStopping counter: 2 out of 50\n",
      "epoch 17\n",
      "Iteration: 500/500Train Loss Calc\n",
      "Iteration: 500/500train mean loss=15.36679465675354, accuracy=0.61408\n",
      "Test Loss Calc\n",
      "Iteration: 100/100test mean loss=15.161495113372803, accuracy=0.5996\n",
      "EarlyStopping counter: 3 out of 50\n",
      "epoch 18\n",
      "Iteration: 500/500Train Loss Calc\n",
      "Iteration: 500/500train mean loss=15.633616769790649, accuracy=0.61042\n",
      "Test Loss Calc\n",
      "Iteration: 100/100test mean loss=15.398832006454468, accuracy=0.5939\n",
      "EarlyStopping counter: 4 out of 50\n",
      "epoch 19\n",
      "Iteration: 500/500Train Loss Calc\n",
      "Iteration: 500/500train mean loss=15.368447584152221, accuracy=0.64464\n",
      "Test Loss Calc\n",
      "Iteration: 100/100test mean loss=15.134818286895753, accuracy=0.6295\n",
      "EarlyStopping counter: 5 out of 50\n",
      "epoch 20\n",
      "Iteration: 500/500Train Loss Calc\n",
      "Iteration: 500/500train mean loss=15.211622133255005, accuracy=0.6588\n",
      "Test Loss Calc\n",
      "Iteration: 100/100test mean loss=14.991620836257935, accuracy=0.6438\n",
      "Validation loss decreased (15.013807 --> 14.991621).  Saving model ...\n",
      "epoch 21\n",
      "Iteration: 500/500Train Loss Calc\n",
      "Iteration: 500/500train mean loss=15.159550151824952, accuracy=0.6796\n",
      "Test Loss Calc\n",
      "Iteration: 100/100test mean loss=14.96116868019104, accuracy=0.6601\n",
      "Validation loss decreased (14.991621 --> 14.961169).  Saving model ...\n",
      "epoch 22\n",
      "Iteration: 500/500Train Loss Calc\n",
      "Iteration: 500/500train mean loss=15.342440675735473, accuracy=0.59078\n",
      "Test Loss Calc\n",
      "Iteration: 100/100test mean loss=15.125675868988036, accuracy=0.58\n",
      "EarlyStopping counter: 1 out of 50\n",
      "epoch 23\n",
      "Iteration: 500/500Train Loss Calc\n",
      "Iteration: 500/500train mean loss=15.235800945281982, accuracy=0.64698\n",
      "Test Loss Calc\n",
      "Iteration: 100/100test mean loss=15.008058729171752, accuracy=0.63\n",
      "EarlyStopping counter: 2 out of 50\n",
      "epoch 24\n",
      "Iteration: 500/500Train Loss Calc\n",
      "Iteration: 500/500train mean loss=15.186014274597168, accuracy=0.62902\n",
      "Test Loss Calc\n",
      "Iteration: 100/100test mean loss=14.987612781524659, accuracy=0.6085\n",
      "EarlyStopping counter: 3 out of 50\n",
      "epoch 25\n",
      "Iteration: 500/500Train Loss Calc\n",
      "Iteration: 500/500train mean loss=15.295383024215699, accuracy=0.66104\n",
      "Test Loss Calc\n",
      "Iteration: 100/100test mean loss=15.132452344894409, accuracy=0.6426\n",
      "EarlyStopping counter: 4 out of 50\n",
      "epoch 26\n",
      "Iteration: 500/500Train Loss Calc\n",
      "Iteration: 500/500train mean loss=15.42426376914978, accuracy=0.58488\n",
      "Test Loss Calc\n",
      "Iteration: 100/100test mean loss=15.200775356292725, accuracy=0.5671\n",
      "EarlyStopping counter: 5 out of 50\n",
      "epoch 27\n",
      "Iteration: 500/500Train Loss Calc\n",
      "Iteration: 500/500train mean loss=15.430245380401612, accuracy=0.61298\n",
      "Test Loss Calc\n",
      "Iteration: 100/100test mean loss=15.210536479949951, accuracy=0.5956\n",
      "EarlyStopping counter: 6 out of 50\n",
      "epoch 28\n",
      "Iteration: 500/500Train Loss Calc\n",
      "Iteration: 500/500train mean loss=15.313068397521972, accuracy=0.66854\n",
      "Test Loss Calc\n",
      "Iteration: 100/100test mean loss=15.073926248550414, accuracy=0.6499\n",
      "EarlyStopping counter: 7 out of 50\n",
      "epoch 29\n",
      "Iteration: 500/500Train Loss Calc\n",
      "Iteration: 500/500train mean loss=15.400150390625, accuracy=0.62838\n",
      "Test Loss Calc\n",
      "Iteration: 100/100test mean loss=15.169874181747437, accuracy=0.614\n",
      "EarlyStopping counter: 8 out of 50\n",
      "epoch 30\n",
      "Iteration: 500/500Train Loss Calc\n",
      "Iteration: 500/500train mean loss=15.445646379470825, accuracy=0.5961\n",
      "Test Loss Calc\n",
      "Iteration: 100/100test mean loss=15.257345314025878, accuracy=0.5834\n",
      "EarlyStopping counter: 9 out of 50\n",
      "epoch 31\n",
      "Iteration: 500/500Train Loss Calc\n",
      "Iteration: 500/500train mean loss=15.216932647705079, accuracy=0.66316\n",
      "Test Loss Calc\n",
      "Iteration: 100/100test mean loss=14.98815258026123, accuracy=0.6461\n",
      "EarlyStopping counter: 10 out of 50\n",
      "epoch 32\n",
      "Iteration: 500/500Train Loss Calc\n",
      "Iteration: 500/500train mean loss=15.772779161453247, accuracy=0.5151\n",
      "Test Loss Calc\n",
      "Iteration: 100/100test mean loss=15.532309560775756, accuracy=0.5034\n",
      "EarlyStopping counter: 11 out of 50\n",
      "epoch 33\n",
      "Iteration: 500/500Train Loss Calc\n",
      "Iteration: 500/500train mean loss=15.64608925628662, accuracy=0.53466\n",
      "Test Loss Calc\n",
      "Iteration: 100/100test mean loss=15.386774730682372, accuracy=0.5179\n",
      "EarlyStopping counter: 12 out of 50\n",
      "epoch 34\n",
      "Iteration: 500/500Train Loss Calc\n",
      "Iteration: 500/500train mean loss=15.480171161651612, accuracy=0.56264\n",
      "Test Loss Calc\n",
      "Iteration: 100/100test mean loss=15.282061309814454, accuracy=0.541\n",
      "EarlyStopping counter: 13 out of 50\n",
      "epoch 35\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 500/500Train Loss Calc\n",
      "Iteration: 500/500train mean loss=15.384271884918213, accuracy=0.61072\n",
      "Test Loss Calc\n",
      "Iteration: 100/100test mean loss=15.164072008132935, accuracy=0.5849\n",
      "EarlyStopping counter: 14 out of 50\n",
      "epoch 36\n",
      "Iteration: 500/500Train Loss Calc\n",
      "Iteration: 500/500train mean loss=15.362185190200806, accuracy=0.60774\n",
      "Test Loss Calc\n",
      "Iteration: 100/100test mean loss=15.165716257095337, accuracy=0.5885\n",
      "EarlyStopping counter: 15 out of 50\n",
      "epoch 37\n",
      "Iteration: 500/500Train Loss Calc\n",
      "Iteration: 500/500train mean loss=15.290136182785034, accuracy=0.65562\n",
      "Test Loss Calc\n",
      "Iteration: 100/100test mean loss=15.07111328125, accuracy=0.6358\n",
      "EarlyStopping counter: 16 out of 50\n",
      "epoch 38\n",
      "Iteration: 500/500Train Loss Calc\n",
      "Iteration: 500/500train mean loss=15.32896315574646, accuracy=0.61296\n",
      "Test Loss Calc\n",
      "Iteration: 100/100test mean loss=15.114369640350342, accuracy=0.5902\n",
      "EarlyStopping counter: 17 out of 50\n",
      "epoch 39\n",
      "Iteration: 500/500Train Loss Calc\n",
      "Iteration: 500/500train mean loss=15.50523405456543, accuracy=0.59502\n",
      "Test Loss Calc\n",
      "Iteration: 100/100test mean loss=15.301544399261475, accuracy=0.5783\n",
      "EarlyStopping counter: 18 out of 50\n",
      "epoch 40\n",
      "Iteration: 500/500Train Loss Calc\n",
      "Iteration: 500/500train mean loss=15.440740871429444, accuracy=0.60882\n",
      "Test Loss Calc\n",
      "Iteration: 100/100test mean loss=15.22582423210144, accuracy=0.5923\n",
      "EarlyStopping counter: 19 out of 50\n",
      "epoch 41\n",
      "Iteration: 500/500Train Loss Calc\n",
      "Iteration: 500/500train mean loss=15.370363592147827, accuracy=0.61122\n",
      "Test Loss Calc\n",
      "Iteration: 100/100test mean loss=15.166906433105469, accuracy=0.6018\n",
      "EarlyStopping counter: 20 out of 50\n",
      "epoch 42\n",
      "Iteration: 500/500Train Loss Calc\n",
      "Iteration: 500/500train mean loss=15.427003662109374, accuracy=0.642\n",
      "Test Loss Calc\n",
      "Iteration: 100/100test mean loss=15.210041513442993, accuracy=0.6212\n",
      "EarlyStopping counter: 21 out of 50\n",
      "epoch 43\n",
      "Iteration: 500/500Train Loss Calc\n",
      "Iteration: 500/500train mean loss=15.208057224273682, accuracy=0.661\n",
      "Test Loss Calc\n",
      "Iteration: 100/100test mean loss=14.981179513931274, accuracy=0.6495\n",
      "EarlyStopping counter: 22 out of 50\n",
      "epoch 44\n",
      "Iteration: 500/500Train Loss Calc\n",
      "Iteration: 500/500train mean loss=15.34521968460083, accuracy=0.61848\n",
      "Test Loss Calc\n",
      "Iteration: 100/100test mean loss=15.115023593902588, accuracy=0.6045\n",
      "EarlyStopping counter: 23 out of 50\n",
      "epoch 45\n",
      "Iteration: 500/500Train Loss Calc\n",
      "Iteration: 500/500train mean loss=15.35320451927185, accuracy=0.65208\n",
      "Test Loss Calc\n",
      "Iteration: 100/100test mean loss=15.139013032913208, accuracy=0.6288\n",
      "EarlyStopping counter: 24 out of 50\n",
      "epoch 46\n",
      "Iteration: 500/500Train Loss Calc\n",
      "Iteration: 500/500train mean loss=15.165446176528931, accuracy=0.61502\n",
      "Test Loss Calc\n",
      "Iteration: 100/100test mean loss=14.988197889328003, accuracy=0.5957\n",
      "EarlyStopping counter: 25 out of 50\n",
      "epoch 47\n",
      "Iteration: 500/500Train Loss Calc\n",
      "Iteration: 500/500train mean loss=15.12003225326538, accuracy=0.65314\n",
      "Test Loss Calc\n",
      "Iteration: 100/100test mean loss=14.972183847427369, accuracy=0.6288\n",
      "EarlyStopping counter: 26 out of 50\n",
      "epoch 48\n",
      "Iteration: 500/500Train Loss Calc\n",
      "Iteration: 500/500train mean loss=15.13567445755005, accuracy=0.69052\n",
      "Test Loss Calc\n",
      "Iteration: 100/100test mean loss=14.93953670501709, accuracy=0.6653\n",
      "Validation loss decreased (14.961169 --> 14.939537).  Saving model ...\n",
      "epoch 49\n",
      "Iteration: 500/500Train Loss Calc\n",
      "Iteration: 500/500train mean loss=15.106223472595214, accuracy=0.6552\n",
      "Test Loss Calc\n",
      "Iteration: 100/100test mean loss=14.872956018447876, accuracy=0.6367\n",
      "Validation loss decreased (14.939537 --> 14.872956).  Saving model ...\n",
      "epoch 50\n",
      "Iteration: 500/500Train Loss Calc\n",
      "Iteration: 500/500train mean loss=15.494186025619507, accuracy=0.59396\n",
      "Test Loss Calc\n",
      "Iteration: 100/100test mean loss=15.292921266555787, accuracy=0.5785\n",
      "EarlyStopping counter: 1 out of 50\n",
      "epoch 51\n",
      "Iteration: 500/500Train Loss Calc\n",
      "Iteration: 500/500train mean loss=15.378357172012329, accuracy=0.62566\n",
      "Test Loss Calc\n",
      "Iteration: 100/100test mean loss=15.145663194656372, accuracy=0.6096\n",
      "EarlyStopping counter: 2 out of 50\n",
      "epoch 52\n",
      "Iteration: 500/500Train Loss Calc\n",
      "Iteration: 500/500train mean loss=15.189357139587402, accuracy=0.65952\n",
      "Test Loss Calc\n",
      "Iteration: 100/100test mean loss=14.9898370552063, accuracy=0.6361\n",
      "EarlyStopping counter: 3 out of 50\n",
      "epoch 53\n",
      "Iteration: 500/500Train Loss Calc\n",
      "Iteration: 500/500train mean loss=15.502640581130981, accuracy=0.5828\n",
      "Test Loss Calc\n",
      "Iteration: 100/100test mean loss=15.265335540771485, accuracy=0.5708\n",
      "EarlyStopping counter: 4 out of 50\n",
      "epoch 54\n",
      "Iteration: 500/500Train Loss Calc\n",
      "Iteration: 500/500train mean loss=15.330437705993653, accuracy=0.64458\n",
      "Test Loss Calc\n",
      "Iteration: 100/100test mean loss=15.101131486892701, accuracy=0.6229\n",
      "EarlyStopping counter: 5 out of 50\n",
      "epoch 55\n",
      "Iteration: 500/500Train Loss Calc\n",
      "Iteration: 500/500train mean loss=15.16825484085083, accuracy=0.6775\n",
      "Test Loss Calc\n",
      "Iteration: 100/100test mean loss=14.945327367782593, accuracy=0.6621\n",
      "EarlyStopping counter: 6 out of 50\n",
      "epoch 56\n",
      "Iteration: 500/500Train Loss Calc\n",
      "Iteration: 500/500train mean loss=15.397551040649414, accuracy=0.5781\n",
      "Test Loss Calc\n",
      "Iteration: 100/100test mean loss=15.19921730041504, accuracy=0.564\n",
      "EarlyStopping counter: 7 out of 50\n",
      "epoch 57\n",
      "Iteration: 500/500Train Loss Calc\n",
      "Iteration: 500/500train mean loss=15.542181190490723, accuracy=0.56474\n",
      "Test Loss Calc\n",
      "Iteration: 100/100test mean loss=15.35079792022705, accuracy=0.5498\n",
      "EarlyStopping counter: 8 out of 50\n",
      "epoch 58\n",
      "Iteration: 500/500Train Loss Calc\n",
      "Iteration: 500/500train mean loss=15.310393018722534, accuracy=0.65256\n",
      "Test Loss Calc\n",
      "Iteration: 100/100test mean loss=15.092316360473633, accuracy=0.6285\n",
      "EarlyStopping counter: 9 out of 50\n",
      "epoch 59\n",
      "Iteration: 500/500Train Loss Calc\n",
      "Iteration: 500/500train mean loss=15.30590093612671, accuracy=0.65166\n",
      "Test Loss Calc\n",
      "Iteration: 100/100test mean loss=15.115029468536378, accuracy=0.6418\n",
      "EarlyStopping counter: 10 out of 50\n",
      "epoch 60\n",
      "Iteration: 500/500Train Loss Calc\n",
      "Iteration: 500/500train mean loss=15.386918546676636, accuracy=0.62122\n",
      "Test Loss Calc\n",
      "Iteration: 100/100test mean loss=15.193652095794677, accuracy=0.5933\n",
      "EarlyStopping counter: 11 out of 50\n",
      "epoch 61\n",
      "Iteration: 500/500Train Loss Calc\n",
      "Iteration: 500/500train mean loss=15.13350567626953, accuracy=0.68932\n",
      "Test Loss Calc\n",
      "Iteration: 100/100test mean loss=14.954582796096801, accuracy=0.6696\n",
      "EarlyStopping counter: 12 out of 50\n",
      "epoch 62\n",
      "Iteration: 500/500Train Loss Calc\n",
      "Iteration: 500/500train mean loss=15.446707447052002, accuracy=0.61248\n",
      "Test Loss Calc\n",
      "Iteration: 100/100test mean loss=15.228203353881836, accuracy=0.5894\n",
      "EarlyStopping counter: 13 out of 50\n",
      "epoch 63\n",
      "Iteration: 500/500Train Loss Calc\n",
      "Iteration: 500/500train mean loss=15.346006334304809, accuracy=0.61758\n",
      "Test Loss Calc\n",
      "Iteration: 100/100test mean loss=15.134433288574218, accuracy=0.6012\n",
      "EarlyStopping counter: 14 out of 50\n",
      "epoch 64\n",
      "Iteration: 500/500Train Loss Calc\n",
      "Iteration: 500/500train mean loss=15.357346084594727, accuracy=0.64302\n",
      "Test Loss Calc\n",
      "Iteration: 100/100test mean loss=15.158528041839599, accuracy=0.6268\n",
      "EarlyStopping counter: 15 out of 50\n",
      "epoch 65\n",
      "Iteration: 500/500Train Loss Calc\n",
      "Iteration: 500/500train mean loss=15.624105291366577, accuracy=0.62652\n",
      "Test Loss Calc\n",
      "Iteration: 100/100test mean loss=15.44269962310791, accuracy=0.6068\n",
      "EarlyStopping counter: 16 out of 50\n",
      "epoch 66\n",
      "Iteration: 500/500Train Loss Calc\n",
      "Iteration: 500/500train mean loss=15.546986591339111, accuracy=0.59974\n",
      "Test Loss Calc\n",
      "Iteration: 100/100test mean loss=15.352188167572022, accuracy=0.5794\n",
      "EarlyStopping counter: 17 out of 50\n",
      "epoch 67\n",
      "Iteration: 500/500Train Loss Calc\n",
      "Iteration: 500/500train mean loss=15.263196699142457, accuracy=0.63948\n",
      "Test Loss Calc\n",
      "Iteration: 100/100test mean loss=15.0657901096344, accuracy=0.6136\n",
      "EarlyStopping counter: 18 out of 50\n",
      "epoch 68\n",
      "Iteration: 500/500Train Loss Calc\n",
      "Iteration: 500/500train mean loss=15.138527864456178, accuracy=0.68878\n",
      "Test Loss Calc\n",
      "Iteration: 100/100test mean loss=14.96980814933777, accuracy=0.6679\n",
      "EarlyStopping counter: 19 out of 50\n",
      "epoch 69\n",
      "Iteration: 500/500Train Loss Calc\n",
      "Iteration: 500/500train mean loss=15.44302371788025, accuracy=0.59198\n",
      "Test Loss Calc\n",
      "Iteration: 100/100test mean loss=15.229976243972779, accuracy=0.5769\n",
      "EarlyStopping counter: 20 out of 50\n",
      "epoch 70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 500/500Train Loss Calc\n",
      "Iteration: 500/500train mean loss=15.212566423416138, accuracy=0.66538\n",
      "Test Loss Calc\n",
      "Iteration: 100/100test mean loss=14.983029308319091, accuracy=0.6514\n",
      "EarlyStopping counter: 21 out of 50\n",
      "epoch 71\n",
      "Iteration: 500/500Train Loss Calc\n",
      "Iteration: 500/500train mean loss=15.352399425506592, accuracy=0.67846\n",
      "Test Loss Calc\n",
      "Iteration: 100/100test mean loss=15.144047708511353, accuracy=0.6554\n",
      "EarlyStopping counter: 22 out of 50\n",
      "epoch 72\n",
      "Iteration: 500/500Train Loss Calc\n",
      "Iteration: 500/500train mean loss=15.208713159561157, accuracy=0.6721\n",
      "Test Loss Calc\n",
      "Iteration: 100/100test mean loss=15.043560724258423, accuracy=0.6565\n",
      "EarlyStopping counter: 23 out of 50\n",
      "epoch 73\n",
      "Iteration: 500/500Train Loss Calc\n",
      "Iteration: 500/500train mean loss=15.497110261917115, accuracy=0.59854\n",
      "Test Loss Calc\n",
      "Iteration: 100/100test mean loss=15.277798137664796, accuracy=0.5766\n",
      "EarlyStopping counter: 24 out of 50\n",
      "epoch 74\n",
      "Iteration: 500/500Train Loss Calc\n",
      "Iteration: 500/500train mean loss=15.48380491065979, accuracy=0.60384\n",
      "Test Loss Calc\n",
      "Iteration: 100/100test mean loss=15.272249536514282, accuracy=0.5868\n",
      "EarlyStopping counter: 25 out of 50\n",
      "epoch 75\n",
      "Iteration: 500/500Train Loss Calc\n",
      "Iteration: 500/500train mean loss=15.357727045059205, accuracy=0.6133\n",
      "Test Loss Calc\n",
      "Iteration: 100/100test mean loss=15.184013261795045, accuracy=0.5958\n",
      "EarlyStopping counter: 26 out of 50\n",
      "epoch 76\n",
      "Iteration: 500/500Train Loss Calc\n",
      "Iteration: 500/500train mean loss=15.271374668121338, accuracy=0.62382\n",
      "Test Loss Calc\n",
      "Iteration: 100/100test mean loss=15.067035102844239, accuracy=0.608\n",
      "EarlyStopping counter: 27 out of 50\n",
      "epoch 77\n",
      "Iteration: 500/500Train Loss Calc\n",
      "Iteration: 500/500train mean loss=15.212306150436401, accuracy=0.67276\n",
      "Test Loss Calc\n",
      "Iteration: 100/100test mean loss=15.023526401519776, accuracy=0.6488\n",
      "EarlyStopping counter: 28 out of 50\n",
      "epoch 78\n",
      "Iteration: 500/500Train Loss Calc\n",
      "Iteration: 500/500train mean loss=15.15528835296631, accuracy=0.6849\n",
      "Test Loss Calc\n",
      "Iteration: 100/100test mean loss=14.937553567886352, accuracy=0.6583\n",
      "EarlyStopping counter: 29 out of 50\n",
      "epoch 79\n",
      "Iteration: 500/500Train Loss Calc\n",
      "Iteration: 500/500train mean loss=15.257310140609741, accuracy=0.64654\n",
      "Test Loss Calc\n",
      "Iteration: 100/100test mean loss=15.093356103897095, accuracy=0.6243\n",
      "EarlyStopping counter: 30 out of 50\n",
      "epoch 80\n",
      "Iteration: 500/500Train Loss Calc\n",
      "Iteration: 500/500train mean loss=15.12457208442688, accuracy=0.69016\n",
      "Test Loss Calc\n",
      "Iteration: 100/100test mean loss=14.89785325050354, accuracy=0.6681\n",
      "EarlyStopping counter: 31 out of 50\n",
      "epoch 81\n",
      "Iteration: 500/500Train Loss Calc\n",
      "Iteration: 500/500train mean loss=15.254423208236695, accuracy=0.66296\n",
      "Test Loss Calc\n",
      "Iteration: 100/100test mean loss=15.044289655685425, accuracy=0.6441\n",
      "EarlyStopping counter: 32 out of 50\n",
      "epoch 82\n",
      "Iteration: 500/500Train Loss Calc\n",
      "Iteration: 500/500train mean loss=15.274462436676025, accuracy=0.64056\n",
      "Test Loss Calc\n",
      "Iteration: 100/100test mean loss=15.077482852935791, accuracy=0.6174\n",
      "EarlyStopping counter: 33 out of 50\n",
      "epoch 83\n",
      "Iteration: 500/500Train Loss Calc\n",
      "Iteration: 500/500train mean loss=15.25873983001709, accuracy=0.65642\n",
      "Test Loss Calc\n",
      "Iteration: 100/100test mean loss=15.024060831069946, accuracy=0.6294\n",
      "EarlyStopping counter: 34 out of 50\n",
      "epoch 84\n",
      "Iteration: 500/500Train Loss Calc\n",
      "Iteration: 500/500train mean loss=15.223086645126342, accuracy=0.68038\n",
      "Test Loss Calc\n",
      "Iteration: 100/100test mean loss=15.028696374893189, accuracy=0.6623\n",
      "EarlyStopping counter: 35 out of 50\n",
      "epoch 85\n",
      "Iteration: 500/500Train Loss Calc\n",
      "Iteration: 500/500train mean loss=15.462203283309936, accuracy=0.60454\n",
      "Test Loss Calc\n",
      "Iteration: 100/100test mean loss=15.23365574836731, accuracy=0.5893\n",
      "EarlyStopping counter: 36 out of 50\n",
      "epoch 86\n",
      "Iteration: 500/500Train Loss Calc\n",
      "Iteration: 500/500train mean loss=15.432928787231445, accuracy=0.66094\n",
      "Test Loss Calc\n",
      "Iteration: 100/100test mean loss=15.20041739463806, accuracy=0.6434\n",
      "EarlyStopping counter: 37 out of 50\n",
      "epoch 87\n",
      "Iteration: 500/500Train Loss Calc\n",
      "Iteration: 500/500train mean loss=15.247789888381957, accuracy=0.63988\n",
      "Test Loss Calc\n",
      "Iteration: 100/100test mean loss=15.058264980316162, accuracy=0.6214\n",
      "EarlyStopping counter: 38 out of 50\n",
      "epoch 88\n",
      "Iteration: 500/500Train Loss Calc\n",
      "Iteration: 500/500train mean loss=15.20186043357849, accuracy=0.65034\n",
      "Test Loss Calc\n",
      "Iteration: 100/100test mean loss=15.052035255432129, accuracy=0.6349\n",
      "EarlyStopping counter: 39 out of 50\n",
      "epoch 89\n",
      "Iteration: 500/500Train Loss Calc\n",
      "Iteration: 500/500train mean loss=15.357499931335449, accuracy=0.62962\n",
      "Test Loss Calc\n",
      "Iteration: 100/100test mean loss=15.15580062866211, accuracy=0.6098\n",
      "EarlyStopping counter: 40 out of 50\n",
      "epoch 90\n",
      "Iteration: 500/500Train Loss Calc\n",
      "Iteration: 500/500train mean loss=15.413598894119263, accuracy=0.62766\n",
      "Test Loss Calc\n",
      "Iteration: 100/100test mean loss=15.197973175048828, accuracy=0.608\n",
      "EarlyStopping counter: 41 out of 50\n",
      "epoch 91\n",
      "Iteration: 500/500Train Loss Calc\n",
      "Iteration: 500/500train mean loss=15.26473593902588, accuracy=0.671\n",
      "Test Loss Calc\n",
      "Iteration: 100/100test mean loss=15.058615283966065, accuracy=0.6549\n",
      "EarlyStopping counter: 42 out of 50\n",
      "epoch 92\n",
      "Iteration: 500/500Train Loss Calc\n",
      "Iteration: 500/500train mean loss=15.59203968811035, accuracy=0.61956\n",
      "Test Loss Calc\n",
      "Iteration: 100/100test mean loss=15.376931676864624, accuracy=0.5949\n",
      "EarlyStopping counter: 43 out of 50\n",
      "epoch 93\n",
      "Iteration: 500/500Train Loss Calc\n",
      "Iteration: 500/500train mean loss=15.45439393234253, accuracy=0.57966\n",
      "Test Loss Calc\n",
      "Iteration: 100/100test mean loss=15.2442436504364, accuracy=0.5573\n",
      "EarlyStopping counter: 44 out of 50\n",
      "epoch 94\n",
      "Iteration: 500/500Train Loss Calc\n",
      "Iteration: 500/500train mean loss=15.493605899810792, accuracy=0.63312\n",
      "Test Loss Calc\n",
      "Iteration: 100/100test mean loss=15.287922477722168, accuracy=0.6159\n",
      "EarlyStopping counter: 45 out of 50\n",
      "epoch 95\n",
      "Iteration: 500/500Train Loss Calc\n",
      "Iteration: 500/500train mean loss=15.179541275024414, accuracy=0.67628\n",
      "Test Loss Calc\n",
      "Iteration: 100/100test mean loss=14.95828164100647, accuracy=0.656\n",
      "EarlyStopping counter: 46 out of 50\n",
      "epoch 96\n",
      "Iteration: 500/500Train Loss Calc\n",
      "Iteration: 500/500train mean loss=15.179184677124024, accuracy=0.6571\n",
      "Test Loss Calc\n",
      "Iteration: 100/100test mean loss=14.976841239929199, accuracy=0.6348\n",
      "EarlyStopping counter: 47 out of 50\n",
      "epoch 97\n",
      "Iteration: 500/500Train Loss Calc\n",
      "Iteration: 500/500train mean loss=15.242971704483033, accuracy=0.66382\n",
      "Test Loss Calc\n",
      "Iteration: 100/100test mean loss=15.040094966888427, accuracy=0.6423\n",
      "EarlyStopping counter: 48 out of 50\n",
      "epoch 98\n",
      "Iteration: 500/500Train Loss Calc\n",
      "Iteration: 500/500train mean loss=15.264294490814208, accuracy=0.6442\n",
      "Test Loss Calc\n",
      "Iteration: 100/100test mean loss=15.064578018188477, accuracy=0.6287\n",
      "EarlyStopping counter: 49 out of 50\n",
      "epoch 99\n",
      "Iteration: 500/500Train Loss Calc\n",
      "Iteration: 500/500train mean loss=15.320225191116332, accuracy=0.60974\n",
      "Test Loss Calc\n",
      "Iteration: 100/100test mean loss=15.126434698104859, accuracy=0.585\n",
      "EarlyStopping counter: 50 out of 50\n",
      "Early stopping\n"
     ]
    }
   ],
   "source": [
    "# training and test\n",
    "for epoch in range(EPOCH):\n",
    "    print('epoch', epoch+1)\n",
    "    \n",
    "    c = 0\n",
    "    for (inputs, labels) in tri_trainloader:\n",
    "        c+=1\n",
    "        print(\"\\rIteration: {}/{}\".format(c, len(tri_trainloader)), end=\"\")\n",
    "        img1_t = inputs[0].to(device)\n",
    "        img2_s = inputs[0].to(device)\n",
    "        img3_s = inputs[1].to(device)\n",
    "        \n",
    "        images = (img1_t, img2_s, img3_s)\n",
    "        \n",
    "        label1_t = labels[0].to(device)\n",
    "        label2_s = labels[0].to(device)\n",
    "        label3_s = labels[1].to(device)\n",
    "        \n",
    "        label = (label1_t, label2_s, label3_s)\n",
    "        \n",
    "        fit.train(images, label, KD_LAMBDA)\n",
    "    c = 0\n",
    "    print(\"Train Loss Calc\")\n",
    "    for (inputs, labels) in tri_trainloader:\n",
    "        c+=1\n",
    "        print(\"\\rIteration: {}/{}\".format(c, len(tri_trainloader)), end=\"\")\n",
    "        img1_t = inputs[0].to(device)\n",
    "        img2_s = inputs[0].to(device)\n",
    "        img3_s = inputs[1].to(device)\n",
    "        \n",
    "        images = (img1_t, img2_s, img3_s)\n",
    "        \n",
    "        label1_t = labels[0].to(device)\n",
    "        label2_s = labels[0].to(device)\n",
    "        label3_s = labels[1].to(device)\n",
    "        \n",
    "        label = (label1_t, label2_s, label3_s)\n",
    "        \n",
    "        losses, corrects = fit.test(images, label, KD_LAMBDA)\n",
    "        \n",
    "        sc.calc_sum(losses, corrects)\n",
    "    \n",
    "    sc.score_print(len(trainset))\n",
    "    sc.score_append(len(trainset))\n",
    "    sc.score_del()\n",
    "    c = 0\n",
    "    print(\"Test Loss Calc\")\n",
    "    for (inputs, labels) in tri_testloader:\n",
    "        c+=1\n",
    "        \n",
    "        print(\"\\rIteration: {}/{}\".format(c, len(tri_testloader)), end=\"\")\n",
    "        img1_t = inputs[0].to(device)\n",
    "        img2_s = inputs[0].to(device)\n",
    "        img3_s = inputs[1].to(device)\n",
    "        \n",
    "        images = (img1_t, img2_s, img3_s)\n",
    "        \n",
    "        label1_t = labels[0].to(device)\n",
    "        label2_s = labels[0].to(device)\n",
    "        label3_s = labels[1].to(device)\n",
    "        \n",
    "        label = (label1_t, label2_s, label3_s)\n",
    "        \n",
    "        losses, corrects = fit.test(images, label, KD_LAMBDA)\n",
    "        \n",
    "        sc.calc_sum(losses, corrects)\n",
    "    \n",
    "    if sc.score_print(len(testset), train = False):\n",
    "      sc.score_append(len(testset), train = False)\n",
    "      sc.score_del()\n",
    "      break\n",
    "\n",
    "    sc.score_append(len(testset), train = False)\n",
    "    sc.score_del()\n",
    "    \n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "v8AwJffQkGIA"
   },
   "outputs": [],
   "source": [
    "# get the scores\n",
    "train_losses, train_corrects = sc.get_value()\n",
    "test_losses, test_corrects = sc.get_value(train = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "hqL5rjHIkXX2"
   },
   "outputs": [],
   "source": [
    "def plot_score(epoch, train_data, test_data, x_lim = None, y_lim = None, x_label = 'EPOCH', y_label = 'score', title = 'score', legend = ['train', 'test'], filename = 'test'):\n",
    "    plt.figure(figsize=(6,6))\n",
    "    \n",
    "    if x_lim is None:\n",
    "        x_lim = epoch\n",
    "    if y_lim is None:\n",
    "        y_lim = 1\n",
    "        \n",
    "    plt.plot(range(epoch), train_data)\n",
    "    plt.plot(range(epoch), test_data, c='#00ff00')\n",
    "    plt.xlim(0, x_lim)\n",
    "    plt.ylim(0, y_lim)\n",
    "    plt.xlabel(x_label)\n",
    "    plt.ylabel(y_label)\n",
    "    plt.legend(legend)\n",
    "    plt.title(title)\n",
    "    plt.savefig(filename+'.png')\n",
    "    plt.close()\n",
    "\n",
    "    \n",
    "def save_data(train_loss, test_loss, train_acc, test_acc, filename):\n",
    "    with open(filename + '.txt', mode='w') as f:\n",
    "        f.write(\"train mean loss={}\\n\".format(train_loss[-1]))\n",
    "        f.write(\"test  mean loss={}\\n\".format(test_loss[-1]))\n",
    "        f.write(\"train accuracy={}\\n\".format(train_acc[-1]))\n",
    "        f.write(\"test  accuracy={}\\n\".format(test_acc[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_s.state_dict(), fnnname + '.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_data(train_losses[0], test_losses[0], train_corrects[0], test_corrects[0], result_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "ojZoGJRRkI9S"
   },
   "outputs": [],
   "source": [
    "# output the glaphs of the scores\n",
    "\n",
    "plot_score(99, train_losses[0], test_losses[0], y_lim = 5.0, y_label = 'LOSS', legend = ['train loss', 'test loss'], title = 'total loss', filename = total_loss_name)\n",
    "\n",
    "plot_score(99, train_losses[1], test_losses[1], y_lim = 5.0, y_label = 'LOSS', legend = ['train loss', 'test loss'], title = 'softmax loss', filename = soft_loss_name)\n",
    "\n",
    "plot_score(99, train_losses[2], test_losses[2], y_lim = 5.0, y_label = 'LOSS', legend = ['train loss', 'test loss'], title = 'triplet loss', filename = tri_loss_name)\n",
    "\n",
    "plot_score(99, train_corrects[0], test_corrects[0], y_lim = 1, y_label = 'ACCURACY', legend = ['train acc', 'test acc'], title = 'accuracy', filename = acc_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "TripletExperiment-Cifar.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "1684bb7895874598b0cb3c8344ce4851": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_185cff25aff34094a39c57dbf63e1975",
       "IPY_MODEL_cd02fad8000c476ebea64496837d52c3",
       "IPY_MODEL_4e65525bb7fa4638964b72c3490847fb"
      ],
      "layout": "IPY_MODEL_cd38ab54d77d4b0eb9f027e96800096a"
     }
    },
    "185cff25aff34094a39c57dbf63e1975": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f77ef129c307426b9aaf83dd61dcc5d5",
      "placeholder": "",
      "style": "IPY_MODEL_7a07a97d997744fab665c96c1f5fe579",
      "value": ""
     }
    },
    "4e65525bb7fa4638964b72c3490847fb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_85f298067f814dd19f731aebea5d6e96",
      "placeholder": "",
      "style": "IPY_MODEL_b372328dca9b49d4960f05df1a50d60a",
      "value": " 170499072/? [00:02&lt;00:00, 56484357.94it/s]"
     }
    },
    "6c49593980e64b7fac5d3ce14efb325c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "7a07a97d997744fab665c96c1f5fe579": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "85f298067f814dd19f731aebea5d6e96": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9c23bae705e54a6084b3fd4282a4ecdc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b372328dca9b49d4960f05df1a50d60a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "cd02fad8000c476ebea64496837d52c3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9c23bae705e54a6084b3fd4282a4ecdc",
      "max": 170498071,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6c49593980e64b7fac5d3ce14efb325c",
      "value": 170498071
     }
    },
    "cd38ab54d77d4b0eb9f027e96800096a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f77ef129c307426b9aaf83dd61dcc5d5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
